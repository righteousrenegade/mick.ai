TRAINER MICK.AI
=========

This is the directory/module that implements the training capabilities for generating your own AI model.

This should probably be considered a branching, but much improved version of the previous scripts. I'll leave the old scripts here in a /deprecated/ directory for housekeeping and posterity. But the synthetic_dat_gen python files have been entirely superseded by a much improved collection of scripts, generated largely with the help of Claude 3.7 Sonnet \<3


FEATURES
-------------
There are four main files/scripts in this incarnation of Mick.AI: 
* processdata.py -- takes a source txt file of raw data and runs it through a local LLM to generate synthetic training data
* cleandata.py -- takes the file generated by processdata.py and cleans up the Q/A pairs to enable them for gpt2-medium training format
* train.py -- uses the output from cleandata.py to train a new model on. if you have CUDA available this can take mere MINUTES to train.
* chat.py -- USE YOUR NEW MODEL!!!! CHAT WITH IT!

If you are starting from scratch to train a model, you will generally use the above scripts in the listed order.



INSTALLATION
-------------
You should just be able to create a virtualenvironment, install dependencies, and train away. For convenience, I've included the `cleaned_trainintdata_high_quality.txt` file which is a Q/A formatted dataset about the Federalist Papers (All copied from my JAImes Madison project, also on github). This dataset can be run out of the box to see the training in action. then you can use the output of that training run immediately with the `chat.py` file.

> python3 -m venv venv
> pip install -r requirements.txt
> source venv/bin/activate # venv/Scripts/Activate.ps1 on windows
> python processdata.py # needs a running llm to connect to, or an api
> python cleandata.py
> python train.py
> python chat.py

If you have trouble with the requirements.txt, you may have to manually install the torch+cuda dependency:
> python -m pip install torch==2.0.1+cu118 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

USAGE
------------

# AI Chat Interface

A GUI application for interacting with GPT-2 based language models, with visualization capabilities for model activations.

## Features

- Modern, user-friendly chat interface
- Message history tracking and export
- Real-time response streaming
- Model activation visualization
- Ability to save and compare activation patterns
- Support for custom models

## Requirements

- Python 3.6+
- PyQt5
- PyTorch
- Transformers
- Matplotlib
- NumPy (version 1.x, not compatible with NumPy 2.x)

## Installation

### Easy Setup (Recommended)

#### Windows
Run the `setup_and_run.bat` script:
```
setup_and_run.bat
```

#### Linux/Mac
Run the `setup_and_run.sh` script:
```bash
chmod +x setup_and_run.sh
./setup_and_run.sh
```

### Manual Installation

1. Create a virtual environment:
```bash
python -m venv venv
```

2. Activate the virtual environment:
   - Windows: `venv\Scripts\activate.bat`
   - Linux/Mac: `source venv/bin/activate`

3. Install the required packages:
```bash
pip install -r requirements.txt
```

4. Run the application:
```bash
python run_chat_gui.py
```

### Known Issues

- **NumPy Compatibility**: This application requires NumPy 1.x and is not compatible with NumPy 2.x. The requirements.txt file specifies `numpy<2.0.0` to ensure compatibility.
- **CUDA Support**: If you want to use GPU acceleration, make sure you have the appropriate CUDA version installed for your PyTorch version.

## Usage

### Chat Interface

- Type your message in the input field and press Enter or click Send
- The AI will generate a response in real-time
- Chat history is maintained during the session
- You can export the chat history to a text or JSON file

### Visualization Features

- Switch to the Visualizations tab to explore model activations
- Select a specific layer from the dropdown menu
- Use the buttons to visualize current activations, save them, or compare with previously saved ones

### Menu Options

- **File**
  - Load Model: Load a custom model
  - Export Chat History: Save the conversation to a file
  - Exit: Close the application
  
- **Settings**
  - Model Settings: Configure model parameters (temperature, max length, etc.)

- **Help**
  - About: Information about the application

## Differences from Original chat.py

This GUI version differs from the original command-line interface in several ways:

1. Removed the "JAImes Madison" persona focus
2. Added a proper message history system
3. Created a modern, user-friendly interface
4. Separated the chat and visualization features into tabs
5. Added export functionality for chat history
6. Improved error handling and user feedback
7. Added threading to prevent UI freezing during generation

## Extending the Application

The code is modular and can be extended with additional features:

- Add more visualization types
- Implement fine-tuning capabilities
- Add support for different model architectures
- Implement chat history persistence between sessions

## Troubleshooting

### NumPy Compatibility Issues

If you encounter issues with NumPy compatibility, ensure you're using NumPy 1.x:
```bash
pip uninstall numpy
pip install "numpy<2.0.0"
```

You can also run the provided fix script:
- Windows: `fix_numpy.bat`
- Linux/Mac: `chmod +x fix_numpy.sh && ./fix_numpy.sh`

### Visualization Issues

If you encounter errors when trying to visualize model activations:

1. **Invalid Shape Error**: This can happen when the activation data has an unexpected shape. The application now includes improved error handling to deal with various data shapes, but if you still encounter issues, try selecting a different layer from the dropdown menu.

2. **No Activations Available**: Make sure to send at least one message before trying to visualize activations, as the model needs to process some input to generate activations.

3. **Matplotlib Errors**: If you encounter matplotlib-related errors, try updating matplotlib:
```bash
pip install --upgrade matplotlib
```

### CUDA Issues

For CUDA issues, you may need to install the specific PyTorch version for your CUDA:
```bash
pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 --index-url https://download.pytorch.org/whl/cu118
```
